{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01d0a07d",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7023b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Setup embedding model\n",
    "from llama_index.core import Settings\n",
    "\n",
    "# Use local embedding models served by LM Studio\n",
    "# Use fake API key (LM Studio doesn't validate it)\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "embed_model = OpenAIEmbedding(\n",
    "    api_base = os.getenv(\"LM_STUDIO_API_BASE\"),\n",
    "    api_key = \"whatever-it-is\",\n",
    "    model_name = os.getenv(\"LM_STUDIO_EMBED_MODEL\"),\n",
    "    embed_batch_size = 100\n",
    ")\n",
    "\n",
    "# Embedding model verification\n",
    "Settings.embed_model = embed_model\n",
    "embed = embed_model.get_text_embedding(\"The quick brown fox jumps over the lazy dog.\")\n",
    "print(embed[:5])  # Should print a list of floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f112655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用智谱免费模型，提取节点关系\n",
    "from llama_index.llms.zhipuai import ZhipuAI\n",
    "llm_extraction = ZhipuAI(\n",
    "    api_key=os.getenv(\"ZHIPU_API_KEY\"),\n",
    "    model=os.getenv(\"ZHIPU_LLM_MODEL_NAME\")\n",
    ")\n",
    "Settings.llm = llm_extraction\n",
    "\n",
    "# Verify the LLM\n",
    "print(llm_extraction.complete(\"\\nBriefly introduce yourself in 50 Chinese characters.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56910fb2",
   "metadata": {},
   "source": [
    "## Pipeline 1: Collecting & preparing the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "# Load documents\n",
    "documents = SimpleDirectoryReader(\"./documents\").load_data()\n",
    "print(documents[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b45ef8",
   "metadata": {},
   "source": [
    "## Pipeline 2: Creating vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceedf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.deeplake import DeepLakeVectorStore\n",
    "from llama_index.core import StorageContext, VectorStoreIndex\n",
    "\n",
    "# Path for vector store and dataset\n",
    "database = \"./dataset/vector_storage\" # local storage\n",
    "vector_store_path = database\n",
    "dataset_path = database\n",
    "\n",
    "# Create an index over the documents\n",
    "# Overwrites the existing dataset if True\n",
    "ow = True\n",
    "\n",
    "if ow==True:\n",
    "    try:\n",
    "        vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=ow)\n",
    "        storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "        index = VectorStoreIndex.from_documents(documents, storage_context, show_progress=True, embed_model=Settings.embed_model)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        print(f\"Error type: {type(e)}\")\n",
    "        print(f\"Error traceback: {e.__traceback__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b9c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplake\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a dictionary to hold the data\n",
    "data = {}\n",
    "\n",
    "# Load vector store data\n",
    "ds = deeplake.load(dataset_path)\n",
    "\n",
    "# Iterate through the tensors in the dataset\n",
    "for tensor_name in ds.tensors:\n",
    "    tensor_data = ds[tensor_name].numpy()\n",
    "\n",
    "    # Check if the tensor is multi-dimensional\n",
    "    if tensor_data.ndim > 1:\n",
    "        # Flatten multi-dimensional tensors\n",
    "        data[tensor_name] = [np.array(e).flatten().tolist() for e in tensor_data]\n",
    "    else:\n",
    "        # Convert 1D tensors directly to lists and decode text\n",
    "        if tensor_name == \"text\":\n",
    "            data[tensor_name] = [t.tobytes().decode('utf-8') if t else \"\" for t in tensor_data]\n",
    "        else:\n",
    "            data[tensor_name] = tensor_data.tolist()\n",
    "\n",
    "# Create a Pandas DataFrame from the dictionary\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd6452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display a selected record\n",
    "def display_record(record_number):\n",
    "    record = df.iloc[record_number]\n",
    "    display_data = {\n",
    "        \"ID\": record.get(\"id\", \"N/A\"),\n",
    "        \"Metadata\": record.get(\"metadata\", \"N/A\"),\n",
    "        \"Text\": record.get(\"text\", \"N/A\"),\n",
    "        \"Embedding\": record.get(\"embedding\", \"N/A\")\n",
    "    }\n",
    "\n",
    "    # Print the ID\n",
    "    print(\"ID:\")\n",
    "    print(display_data[\"ID\"])\n",
    "    print()\n",
    "\n",
    "    # Print the metadata in a structured format\n",
    "    print(\"Metadata:\")\n",
    "    metadata = display_data[\"Metadata\"]\n",
    "    if isinstance(metadata, list):\n",
    "        for item in metadata:\n",
    "            for key, value in item.items():\n",
    "                print(f\"{key}: {value}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(metadata)\n",
    "    print()\n",
    "\n",
    "    # Print the text\n",
    "    print(\"Text:\")\n",
    "    print(display_data[\"Text\"])\n",
    "    print()\n",
    "\n",
    "    # Print the embedding\n",
    "    print(\"Embedding:\")\n",
    "    print(display_data[\"Embedding\"])\n",
    "    print()\n",
    "\n",
    "# Example usage\n",
    "rec = 7  # Replace with the desired record number\n",
    "display_record(rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a9728a",
   "metadata": {},
   "source": [
    "## Pipeline 3: Knowledge graph index-based RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26db46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "# Ensure 'text' column is of type string\n",
    "df['text'] = df['text'].astype(str)\n",
    "# Create documents with IDs\n",
    "documents = [Document(text=row['text'], doc_id=str(row['id'])) for _, row in df.iterrows()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff84fe2",
   "metadata": {},
   "source": [
    "### Generating the graph index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e469233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import KnowledgeGraphIndex\n",
    "import time\n",
    "from typing import List\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "class RobustKnowledgeGraphIndex(KnowledgeGraphIndex):\n",
    "    def _extract_triplets(self, text: str) -> List[tuple]:\n",
    "        \"\"\"Extract triplets with error handling to ignore failures.\"\"\"\n",
    "        try:\n",
    "            # Call the parent class's triplet extraction method\n",
    "            return super()._extract_triplets(text)\n",
    "        except Exception as e:\n",
    "            # Log the error (optional) and return an empty list to continue processing\n",
    "            print(f\"Error extracting triplets for text chunk: {e}\")\n",
    "            return []\n",
    "\n",
    "# Graph index with embeddings\n",
    "graph_index = RobustKnowledgeGraphIndex.from_documents(\n",
    "    documents,\n",
    "    max_triplets_per_chunk=5,\n",
    "    include_embeddings=True,\n",
    "    show_progress=False,\n",
    ")\n",
    "\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the execution time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Index creation time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "print(type(graph_index))\n",
    "\n",
    "# Save the graph index to a file\n",
    "graph_index_saving_path = \"./dataset/graph_storage\"\n",
    "graph_index.storage_context.persist(persist_dir=graph_index_saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bfe516",
   "metadata": {},
   "source": [
    "### Displaying the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278073b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Graph data\n",
    "from llama_index.core import StorageContext, load_index_from_storage\n",
    "\n",
    "graph_index_saving_path = \"./dataset/graph_storage\"\n",
    "storage_context = StorageContext.from_defaults(persist_dir=graph_index_saving_path)\n",
    "\n",
    "graph_index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Create graph\n",
    "from pyvis.network import Network\n",
    "\n",
    "g = graph_index.get_networkx_graph()\n",
    "net = Network(notebook=True, cdn_resources=\"in_line\", directed=True)\n",
    "net.from_nx(g)\n",
    "\n",
    "# Set node and edge properties: colors and sizes\n",
    "for node in net.nodes:\n",
    "    node['color'] = 'lightgray'\n",
    "    node['size'] = 10\n",
    "\n",
    "for edge in net.edges:\n",
    "    edge['color'] = 'black'\n",
    "    edge['width'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c253e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fgraph=\"Knowledge_graph_\"+ topic_name + \".html\"\n",
    "net.write_html(fgraph)\n",
    "print(fgraph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cca3cb",
   "metadata": {},
   "source": [
    "## Interacting with the Knowledge graph index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb36af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import textwrap\n",
    "\n",
    "from llama_index.core import StorageContext, load_graph_from_storage\n",
    "\n",
    "graph_saving_path = \"./dataset/graph_index\"\n",
    "storage_context = StorageContext.from_defaults(persist_dir=graph_saving_path)\n",
    "graph_index = load_graph_from_storage(storage_context, 0)\n",
    "\n",
    "def execute_query(user_input, k=3, temp=0.1, mt=1024):\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Execute the query with additional parameters\n",
    "    response = graph_query_engine.query(user_input)\n",
    "\n",
    "    # Stop the timer\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate and print the execution time\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "    # Print the response, wrapped to 100 characters per line\n",
    "    print(textwrap.fill(str(response), 100))\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query=\"What is the primary goal of bifacial panels? And what solar cells can be used for this type of panel?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f637428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import textwrap\n",
    "import sys\n",
    "import io\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "# Capture the output\n",
    "old_stdout = sys.stdout\n",
    "new_stdout = io.StringIO()\n",
    "sys.stdout = new_stdout\n",
    "response = execute_query(user_query)\n",
    "# Restore stdout\n",
    "sys.stdout = old_stdout\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "# Calculate and print the execution time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "print(textwrap.fill(str(response), 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df062845",
   "metadata": {},
   "source": [
    "### Similarity re-rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79ec26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('Qwen/Qwen3-Embedding-0.6B')\n",
    "\n",
    "def calculate_cosine_similarity_with_embeddings(text1, text2):\n",
    "    embeddings1 = model.encode(text1)\n",
    "    embeddings2 = model.encode(text2)\n",
    "    similarity = cosine_similarity([embeddings1], [embeddings2])\n",
    "    return similarity[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6545595",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import textwrap\n",
    "import sys\n",
    "import io\n",
    "\n",
    "user_query=\"Which experts are often associated with Solar Cell theory?\"\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "# Capture the output\n",
    "old_stdout = sys.stdout\n",
    "new_stdout = io.StringIO()\n",
    "sys.stdout = new_stdout\n",
    "response = execute_query(user_query)\n",
    "# Restore stdout\n",
    "sys.stdout = old_stdout\n",
    "# Stop the timer\n",
    "end_time = time.time()\n",
    "# Calculate and print the execution time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Query execution time: {elapsed_time:.4f} seconds\")\n",
    "\n",
    "print(textwrap.fill(str(response), 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
