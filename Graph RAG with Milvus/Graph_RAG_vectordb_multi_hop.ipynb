{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd2fb4e1",
   "metadata": {},
   "source": [
    "This notebook presents a unified approach that achieves Graph RAG capabilities using only a vector database, eliminating the need for separate graph databases while maintaining superior performance.\n",
    "\n",
    "1. Offline data preparation\n",
    "    - Extract entities and relationships from text corpus\n",
    "    - Create three vector collections: entities, relationships, and passages\n",
    "    - Build adjacency mapping between entities and relationships\n",
    "2. Query-time retrieval\n",
    "    - Retrieve similar entities and relationships using vector similarity search\n",
    "    - Use NER to identify query entities\n",
    "3. Subgraph Expansion\n",
    "    - Expand retrieved entities/relationships to their neighbourhood using adjacency matrices\n",
    "    - Support multi-degree expansion (1-hop, 2-hop neighbours)\n",
    "    - Merge results from both entity and relationship expansion path\n",
    "4. LLM re-ranking\n",
    "    - Use large language models to intelligently filter and rank candidate relationships\n",
    "    - Apple CoT reasoning to select most relevant relationships\n",
    "    - Return final passages for answer generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ec0f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "from pymilvus import MilvusClient\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "from langchain_community.chat_models import ChatZhipuAI\n",
    "from langchain_localai import LocalAIEmbeddings\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "milvus_client = MilvusClient(\n",
    "    uri=os.getenv(\"ZILLIZ_MILVUS_PUBLIC_ENDPOINT\"),\n",
    "    token=os.getenv(\"ZILLIZ_TOKEN\")\n",
    ")\n",
    "\n",
    "llm = ChatZhipuAI(\n",
    "    api_key=os.getenv(\"ZHIPU_API_KEY\"),\n",
    "    model=os.getenv(\"ZHIPU_LLM_MODEL_NAME\"),\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "embedding_model = LocalAIEmbeddings(\n",
    "    openai_api_base=os.getenv(\"LM_STUDIO_API_BASE\"),\n",
    "    openai_api_key=\"nothing at all\",\n",
    "    model=os.getenv(\"LM_STUDIO_EMBED_MODEL\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282c406",
   "metadata": {},
   "source": [
    "## Offline data loading\n",
    "\n",
    "Data structure:\n",
    "1. **Entities**: The \"nodes\" of our conceptual graph - people, places, concepts, etc.\n",
    "2. **Relationships**: The \"edges\" connecting entities - these are full triplets (subject-predicate-object)\n",
    "3. **Passages**: The original text documents that provide context and detailed information\n",
    "\n",
    "**Why This Structure Works**: By separating entities and relationships into distinct vector collections, we can perform targeted searches for different aspects of a query. When a user asks \"What contribution did the son of Euler's teacher make?\", we can:\n",
    "- Find entities related to \"Euler\" \n",
    "- Find relationships that connect teacher-student and parent-child concepts\n",
    "- Expand the graph to discover indirect connections\n",
    "- Retrieve the most relevant passages for final answer generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb23b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nano_dataset = [\n",
    "    {\n",
    "        \"passage\": \"Jakob Bernoulli (1654–1705): Jakob was one of the earliest members of the Bernoulli family to gain prominence in mathematics. He made significant contributions to calculus, particularly in the development of the theory of probability. He is known for the Bernoulli numbers and the Bernoulli theorem, a precursor to the law of large numbers. He was the older brother of Johann Bernoulli, another influential mathematician, and the two had a complex relationship that involved both collaboration and rivalry.\",\n",
    "        \"triplets\": [\n",
    "            [\"Jakob Bernoulli\", \"made significant contributions to\", \"calculus\"],\n",
    "            [\n",
    "                \"Jakob Bernoulli\",\n",
    "                \"made significant contributions to\",\n",
    "                \"the theory of probability\",\n",
    "            ],\n",
    "            [\"Jakob Bernoulli\", \"is known for\", \"the Bernoulli numbers\"],\n",
    "            [\"Jakob Bernoulli\", \"is known for\", \"the Bernoulli theorem\"],\n",
    "            [\"The Bernoulli theorem\", \"is a precursor to\", \"the law of large numbers\"],\n",
    "            [\"Jakob Bernoulli\", \"was the older brother of\", \"Johann Bernoulli\"],\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"passage\": \"Johann Bernoulli (1667–1748): Johann, Jakob’s younger brother, was also a major figure in the development of calculus. He worked on infinitesimal calculus and was instrumental in spreading the ideas of Leibniz across Europe. Johann also contributed to the calculus of variations and was known for his work on the brachistochrone problem, which is the curve of fastest descent between two points.\",\n",
    "        \"triplets\": [\n",
    "            [\n",
    "                \"Johann Bernoulli\",\n",
    "                \"was a major figure of\",\n",
    "                \"the development of calculus\",\n",
    "            ],\n",
    "            [\"Johann Bernoulli\", \"was\", \"Jakob's younger brother\"],\n",
    "            [\"Johann Bernoulli\", \"worked on\", \"infinitesimal calculus\"],\n",
    "            [\"Johann Bernoulli\", \"was instrumental in spreading\", \"Leibniz's ideas\"],\n",
    "            [\"Johann Bernoulli\", \"contributed to\", \"the calculus of variations\"],\n",
    "            [\"Johann Bernoulli\", \"was known for\", \"the brachistochrone problem\"],\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"passage\": \"Daniel Bernoulli (1700–1782): The son of Johann Bernoulli, Daniel made major contributions to fluid dynamics, probability, and statistics. He is most famous for Bernoulli’s principle, which describes the behavior of fluid flow and is fundamental to the understanding of aerodynamics.\",\n",
    "        \"triplets\": [\n",
    "            [\"Daniel Bernoulli\", \"was the son of\", \"Johann Bernoulli\"],\n",
    "            [\"Daniel Bernoulli\", \"made major contributions to\", \"fluid dynamics\"],\n",
    "            [\"Daniel Bernoulli\", \"made major contributions to\", \"probability\"],\n",
    "            [\"Daniel Bernoulli\", \"made major contributions to\", \"statistics\"],\n",
    "            [\"Daniel Bernoulli\", \"is most famous for\", \"Bernoulli’s principle\"],\n",
    "            [\n",
    "                \"Bernoulli’s principle\",\n",
    "                \"is fundamental to\",\n",
    "                \"the understanding of aerodynamics\",\n",
    "            ],\n",
    "        ],\n",
    "    },\n",
    "    {\n",
    "        \"passage\": \"Leonhard Euler (1707–1783) was one of the greatest mathematicians of all time, and his relationship with the Bernoulli family was significant. Euler was born in Basel and was a student of Johann Bernoulli, who recognized his exceptional talent and mentored him in mathematics. Johann Bernoulli’s influence on Euler was profound, and Euler later expanded upon many of the ideas and methods he learned from the Bernoullis.\",\n",
    "        \"triplets\": [\n",
    "            [\n",
    "                \"Leonhard Euler\",\n",
    "                \"had a significant relationship with\",\n",
    "                \"the Bernoulli family\",\n",
    "            ],\n",
    "            [\"leonhard Euler\", \"was born in\", \"Basel\"],\n",
    "            [\"Leonhard Euler\", \"was a student of\", \"Johann Bernoulli\"],\n",
    "            [\"Johann Bernoulli's influence\", \"was profound on\", \"Euler\"],\n",
    "        ],\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f514b2e",
   "metadata": {},
   "source": [
    "## Building the Knowledge Graph structure\n",
    "\n",
    "Transform the triplets into a searchable vector while maintaining the graph connectivity information. This process involves several key decisions:\n",
    "\n",
    "**Entity Extraction Strategy**: We extract unique entities by collecting all subjects and objects from our triplets. This ensures we capture every entity mentioned in any relationship, creating comprehensive coverage of our knowledge domain.\n",
    "\n",
    "**Relationship Representation**: Rather than storing relationships as separate subject-predicate-object components, we concatenate them into natural language sentences. For example, `[\"Jakob Bernoulli\", \"was the older brother of\", \"Johann Bernoulli\"]` becomes `\"Jakob Bernoulli was the older brother of Johann Bernoulli\"`. This approach offers several advantages:\n",
    "- **Semantic richness**: The full sentence provides more context for vector embeddings\n",
    "- **Natural language compatibility**: LLMs can easily understand and reason about complete sentences\n",
    "- **Reduced complexity**: No need to manage separate predicate vocabularies\n",
    "\n",
    "**Adjacency Mapping Construction**: We build two critical mapping structures:\n",
    "1. **`entityid_2_relationids`**: Maps each entity to all relationships it participates in (enables entity-to-relationship expansion)\n",
    "2. **`relationid_2_passageids`**: Maps each relationship to the passages where it appears (enables relationship-to-passage retrieval)\n",
    "\n",
    "These mappings are essential for the subgraph expansion process, allowing us to efficiently traverse the conceptual graph during query time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c088f70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entityid_2_relationids = defaultdict(list)\n",
    "relationid_2_passageids = defaultdict(list)\n",
    "\n",
    "entities = []\n",
    "relations = []\n",
    "passages = []\n",
    "for passage_id, dataset_info in enumerate(nano_dataset):\n",
    "    passage, triplets = dataset_info[\"passage\"], dataset_info[\"triplets\"]\n",
    "    passages.append(passage)\n",
    "    for triplet in triplets:\n",
    "        if triplet[0] not in entities:\n",
    "            entities.append(triplet[0])\n",
    "        if triplet[2] not in entities:\n",
    "            entities.append(triplet[2])\n",
    "        relation = \" \".join(triplet)\n",
    "        if relation not in relations:\n",
    "            relations.append(relation)\n",
    "            entityid_2_relationids[entities.index(triplet[0])].append(\n",
    "                len(relations) - 1\n",
    "            )\n",
    "            entityid_2_relationids[entities.index(triplet[2])].append(\n",
    "                len(relations) - 1\n",
    "            )\n",
    "        relationid_2_passageids[relations.index(relation)].append(passage_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec342fc5",
   "metadata": {},
   "source": [
    "## Data insertion\n",
    "\n",
    "Create Milvus collections for entity, relation, and passage. We create three separate Milvus collections, each optimized for different types of retrieval:\n",
    "\n",
    "1. **Entity Collection**: Stores vector embeddings of entity names and descriptions\n",
    "   - **Purpose**: Enables entity-centric queries like \"find entities similar to 'Euler'\"\n",
    "   - **Search pattern**: Direct semantic similarity to query entities\n",
    "\n",
    "2. **Relationship Collection**: Stores vector embeddings of complete relationship sentences  \n",
    "   - **Purpose**: Captures semantic patterns in relationships that match query intent\n",
    "   - **Search pattern**: Finds relationships semantically similar to the entire query\n",
    "\n",
    "3. **Passage Collection**: Stores vector embeddings of original text passages\n",
    "   - **Purpose**: Provides comparison baseline and detailed context for final answers\n",
    "   - **Search pattern**: Traditional RAG-style document retrieval\n",
    "\n",
    "**Why Three Collections?** This separation allows for **multi-modal retrieval**:\n",
    "- If a query mentions specific entities, we retrieve through the entity collection\n",
    "- If a query describes relationships or actions, we retrieve through the relationship collection  \n",
    "- We can combine results from both paths and compare against traditional passage retrieval\n",
    "\n",
    "**Embedding Consistency**: All collections use the same embedding model to ensure compatibility during similarity searches and result merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ad2dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = len(embedding_model.embed_query(\"foo\"))\n",
    "\n",
    "\n",
    "def create_milvus_collection(collection_name: str):\n",
    "    \"\"\"\n",
    "    Create a new Milvus collection with specified configuration.\n",
    "    \n",
    "    This function creates a new Milvus collection for storing vector embeddings.\n",
    "    If a collection with the same name already exists, it will be dropped first\n",
    "    to ensure a clean state.\n",
    "    \n",
    "    Args:\n",
    "        collection_name (str): The name of the collection to create.\n",
    "    \"\"\"\n",
    "    if milvus_client.has_collection(collection_name=collection_name):\n",
    "        milvus_client.drop_collection(collection_name=collection_name)\n",
    "    milvus_client.create_collection(\n",
    "        collection_name=collection_name,\n",
    "        dimension=embedding_dim,\n",
    "        consistency_level=\"Strong\",\n",
    "    )\n",
    "\n",
    "\n",
    "entity_col_name = \"entity_collection\"\n",
    "relation_col_name = \"relation_collection\"\n",
    "passage_col_name = \"passage_collection\"\n",
    "create_milvus_collection(entity_col_name)\n",
    "create_milvus_collection(relation_col_name)\n",
    "create_milvus_collection(passage_col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07a34fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inserting: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n",
      "Inserting: 100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n",
      "Inserting: 100%|██████████| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "source": [
    "def milvus_insert(\n",
    "    collection_name: str,\n",
    "    text_list: list[str],\n",
    "):\n",
    "    \"\"\"\n",
    "    Insert text data with embeddings into a Milvus collection in batches.\n",
    "    \n",
    "    This function processes a list of text strings, generates embeddings for them,\n",
    "    and inserts the data into the specified Milvus collection in batches for\n",
    "    efficient processing.\n",
    "    \n",
    "    Args:\n",
    "        collection_name (str): The name of the Milvus collection to insert data into.\n",
    "        text_list (list[str]): A list of text strings to be embedded and inserted.\n",
    "    \"\"\"\n",
    "    batch_size = 512\n",
    "    for row_id in tqdm(range(0, len(text_list), batch_size), desc=\"Inserting\"):\n",
    "        batch_texts = text_list[row_id : row_id + batch_size]\n",
    "        batch_embeddings = embedding_model.embed_documents(batch_texts)\n",
    "\n",
    "        batch_ids = [row_id + j for j in range(len(batch_texts))]\n",
    "        batch_data = [\n",
    "            {\n",
    "                \"id\": id_,\n",
    "                \"text\": text,\n",
    "                \"vector\": vector,\n",
    "            }\n",
    "            for id_, text, vector in zip(batch_ids, batch_texts, batch_embeddings)\n",
    "        ]\n",
    "        milvus_client.insert(\n",
    "            collection_name=collection_name,\n",
    "            data=batch_data,\n",
    "        )\n",
    "\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=relation_col_name,\n",
    "    text_list=relations,\n",
    ")\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=entity_col_name,\n",
    "    text_list=entities,\n",
    ")\n",
    "\n",
    "milvus_insert(\n",
    "    collection_name=passage_col_name,\n",
    "    text_list=passages,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a94df98",
   "metadata": {},
   "source": [
    "## Online querying\n",
    "\n",
    "### Understanding the querying processing pipeline\n",
    "1. **Entity Identification**: Extract entities mentioned in the query using NER\n",
    "2. **Dual Retrieval**: Search both entity and relationship collections simultaneously  \n",
    "3. **Graph Expansion**: Use adjacency information to discover indirect connections\n",
    "4. **LLM Reranking**: Apply intelligent filtering to select the most relevant relationships\n",
    "5. **Answer Generation**: Retrieve final passages and generate the response\n",
    "\n",
    "### Similarity retrieval\n",
    "We retrieve the topK similar entities and relations based on the input query from Milvus.\n",
    "\n",
    "When performing the entity retrieving, we should first extract the query entities from the query text using some specific method like NER. In practise, you can use any other model or approach to extract the entities from the query.\n",
    "\n",
    "### Dual-path retrieval strategy\n",
    "**Path 1: Entity-Based Retrieval**\n",
    "- **Input**: Extracted entities from the query (using NER)  \n",
    "- **Process**: Find entities in our knowledge base similar to query entities\n",
    "- **Why NER?**: Many complex queries reference specific entities (\"Euler\", \"Bernoulli family\"). By identifying these explicitly, we can find direct matches and their associated relationships\n",
    "- **Example**: For \"What contribution did the son of Euler's teacher make?\", NER identifies \"Euler\" as a key entity\n",
    "\n",
    "**Path 2: Relationship-Based Retrieval**  \n",
    "- **Input**: The complete query text\n",
    "- **Process**: Find relationships that semantically match the query's intent\n",
    "- **Purpose**: Captures the relational patterns and question structure\n",
    "- **Example**: The query pattern \"contribution did the son of X's teacher make\" matches relationship patterns about family\n",
    "\n",
    "**Benefits of Dual Retrieval**:\n",
    "- **Comprehensive coverage**: Entity path catches direct mentions, relationship path catches semantic patterns\n",
    "- **Redundancy for robustness**: If one path misses relevant information, the other might capture it\n",
    "- **Different granularities**: Entities provide specific anchors, relationships provide structural patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8cf5a415",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What contribution did the son of Euler's teacher make?\"\n",
    "\n",
    "query_ner_list = [\"Euler\"]\n",
    "# query_ner_list = ner(query) # In practice, replace it with your custom NER approach\n",
    "\n",
    "query_ner_embeddings = [\n",
    "    embedding_model.embed_query(query_ner) for query_ner in query_ner_list\n",
    "]\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "entity_search_res = milvus_client.search(\n",
    "    collection_name=entity_col_name,\n",
    "    data=query_ner_embeddings,\n",
    "    limit=top_k,\n",
    "    output_fields=[\"id\"],\n",
    ")\n",
    "\n",
    "query_embedding = embedding_model.embed_query(query)\n",
    "\n",
    "relation_search_res = milvus_client.search(\n",
    "    collection_name=relation_col_name,\n",
    "    data=[query_embedding],\n",
    "    limit=top_k,\n",
    "    output_fields=[\"id\"],\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c99a96",
   "metadata": {},
   "source": [
    "### Expand subgraph\n",
    "\n",
    "We use the retrieved entities and relations to expand the subgraph and obtain the candidate relationships, and then merge them from the two ways.\n",
    "\n",
    "Here we construct an adjacency matrix and use matrix multiplication to calculate the adjacency mapping information within a few degrees. In this way, we can quickly obtain information of any degree of expansion.\n",
    "\n",
    "### The Mathematics of Graph Expansion\n",
    "\n",
    "The subgraph expansion step is where our approach truly shines. Instead of storing an explicit graph database, we use **adjacency matrices** and **matrix multiplication** to efficiently compute multi-hop relationships. This mathematical approach offers several advantages:\n",
    "\n",
    "**Adjacency Matrix Construction**: We create a binary matrix where `entity_relation_adj[i][j] = 1` if entity `i` participates in relationship `j`, and 0 otherwise. This sparse representation captures the entire graph structure.\n",
    "\n",
    "**Multi-Degree Expansion via Matrix Powers**:\n",
    "- **1-degree expansion**: `entity_adj_1_degree = entity_relation_adj @ entity_relation_adj.T`\n",
    "- **2-degree expansion**: `entity_adj_2_degree = entity_adj_1_degree @ entity_adj_1_degree`  \n",
    "- **n-degree expansion**: Computed by raising the 1-degree matrix to the nth power\n",
    "\n",
    "**Why This Works**: Matrix multiplication naturally implements graph traversal. When we multiply adjacency matrices, we're computing paths through the graph:\n",
    "- 1-hop: Directly connected entities/relationships\n",
    "- 2-hop: Entities connected through one intermediate entity  \n",
    "- n-hop: Entities connected through (n-1) intermediate steps\n",
    "\n",
    "**Computational Efficiency**: Using sparse matrices and vectorized operations, we can expand subgraphs containing thousands of entities in milliseconds, making this approach highly scalable.\n",
    "\n",
    "**Dual Expansion Strategy**: We expand from both retrieved entities AND retrieved relationships, then merge the results. This ensures we capture relevant information regardless of whether the initial retrieval was more successful on the entity or relationship side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2791733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the adjacency matrix of entities and relations where the value of the adjacency matrix is 1 if an entity is related to a relation, otherwise 0.\n",
    "entity_relation_adj = np.zeros((len(entities), len(relations)))\n",
    "for entity_id, entity in enumerate(entities):\n",
    "    entity_relation_adj[entity_id, entityid_2_relationids[entity_id]] = 1\n",
    "\n",
    "# Convert the adjacency matrix to a sparse matrix for efficient computation.\n",
    "entity_relation_adj = csr_matrix(entity_relation_adj)\n",
    "\n",
    "# Use the entity-relation adjacency matrix to construct 1 degree entity-entity and relation-relation adjacency matrices.\n",
    "entity_adj_1_degree = entity_relation_adj @ entity_relation_adj.T\n",
    "relation_adj_1_degree = entity_relation_adj.T @ entity_relation_adj\n",
    "\n",
    "# Specify the target degree of the subgraph to be expanded.\n",
    "# 1 or 2 is enough for most cases.\n",
    "target_degree = 2\n",
    "\n",
    "# Compute the target degree adjacency matrices using matrix multiplication.\n",
    "entity_adj_target_degree = entity_adj_1_degree\n",
    "for _ in range(target_degree - 1):\n",
    "    entity_adj_target_degree = entity_adj_target_degree * entity_adj_1_degree\n",
    "relation_adj_target_degree = relation_adj_1_degree\n",
    "for _ in range(target_degree - 1):\n",
    "    relation_adj_target_degree = relation_adj_target_degree * relation_adj_1_degree\n",
    "\n",
    "entity_relation_adj_target_degree = entity_adj_target_degree @ entity_relation_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a085b5",
   "metadata": {},
   "source": [
    "By taking the value from the target degree expansion matrix, we can easily expand the corresponding degree from the retrieved entity and relations to obtain all relations of the subgraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b7d6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_relations_from_relation = set()\n",
    "expanded_relations_from_entity = set()\n",
    "\n",
    "filtered_hit_relation_ids = [\n",
    "    relation_res[\"entity\"][\"id\"]\n",
    "    for relation_res in relation_search_res\n",
    "]\n",
    "for hit_relation_id in filtered_hit_relation_ids:\n",
    "    expanded_relations_from_relation.update(\n",
    "        relation_adj_target_degree[hit_relation_id].nonzero()[1].tolist()\n",
    "    )\n",
    "\n",
    "filtered_hit_entity_ids = [\n",
    "    one_entity_res[\"entity\"][\"id\"]\n",
    "    for one_entity_search_res in entity_search_res\n",
    "    for one_entity_res in one_entity_search_res\n",
    "]\n",
    "\n",
    "for filtered_hit_entity_id in filtered_hit_entity_ids:\n",
    "    expanded_relations_from_entity.update(\n",
    "        entity_relation_adj_target_degree[filtered_hit_entity_id].nonzero()[1].tolist()\n",
    "    )\n",
    "\n",
    "# Merge the expanded relations from the relation and entity retrieval ways.\n",
    "relation_candidate_ids = list(\n",
    "    expanded_relations_from_relation | expanded_relations_from_entity\n",
    ")\n",
    "\n",
    "relation_candidate_texts = [\n",
    "    relations[relation_id] for relation_id in relation_candidate_ids\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54405d",
   "metadata": {},
   "source": [
    "We have get the candidate relationship by expanding the subgraph, which will be re-ranked by LLm in the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebb38b4",
   "metadata": {},
   "source": [
    "### LLM Reranking\n",
    "\n",
    "In this stage, we deploy the powerful self-attention mechanism of LLM to further filter and refine the candidate set of relationships. The subgraph expansion step provides us with many potentially relevant relationships, but not all of them are equally useful for answering our specific query. This is where **Large Language Models** excel - they can understand the semantic meaning of both the query and the candidate relationships, then intelligently select the most relevant ones.\n",
    "\n",
    "**Why LLM Re-ranking is Necessary**:\n",
    "- **Semantic understanding**: LLMs can understand complex query intentions that pure similarity search might miss\n",
    "- **Multi-hop reasoning**: LLMs can trace logical connections across multiple relationships\n",
    "- **Context awareness**: LLMs consider how relationships work together to answer the query\n",
    "- **Quality filtering**: LLMs can identify and prioritize the most informative relationships\n",
    "\n",
    "**Chain-of-Thought Prompting Strategy**:\n",
    "We use a structured approach that encourages the LLM to:\n",
    "1. **Analyze the query**: Break down what information is needed to answer the question\n",
    "2. **Identify key connections**: Determine which types of relationships would be most helpful  \n",
    "3. **Reason about relevance**: Explain why specific relationships are chosen\n",
    "4. **Rank by importance**: Order relationships by their utility for the final answer\n",
    "\n",
    "**One-Shot Learning Pattern**: We provide a concrete example of the reasoning process to guide the LLM's behaviour. This example demonstrates how to identify core entities, trace multi-hop connections, and prioritize the most direct relationships.\n",
    "\n",
    "**JSON Output Format**: By requiring structured JSON output, we ensure reliable parsing and consistent results, making the system robust for production use.\n",
    "\n",
    "#### Define One-Shot Learning Examples\n",
    "\n",
    "First, we prepare the one-shot learning examples to guide the LLM's reasoning process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39db7b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt_one_shot_input = \"\"\"I will provide you with a list of relationship descriptions. Your task is to select 3 relationships that may be useful to answer the given question. Please return a JSON object containing your thought process and a list of the selected relationships in order of their relevance.\n",
    "\n",
    "Question:\n",
    "When was the mother of the leader of the Third Crusade born?\n",
    "\n",
    "Relationship descriptions:\n",
    "[1] Eleanor was born in 1122.\n",
    "[2] Eleanor married King Louis VII of France.\n",
    "[3] Eleanor was the Duchess of Aquitaine.\n",
    "[4] Eleanor participated in the Second Crusade.\n",
    "[5] Eleanor had eight children.\n",
    "[6] Eleanor was married to Henry II of England.\n",
    "[7] Eleanor was the mother of Richard the Lionheart.\n",
    "[8] Richard the Lionheart was the King of England.\n",
    "[9] Henry II was the father of Richard the Lionheart.\n",
    "[10] Henry II was the King of England.\n",
    "[11] Richard the Lionheart led the Third Crusade.\n",
    "\n",
    "\"\"\"\n",
    "query_prompt_one_shot_output = \"\"\"{\"thought_process\": \"To answer the question about the birth of the mother of the leader of the Third Crusade, I first need to identify who led the Third Crusade and then determine who his mother was. After identifying his mother, I can look for the relationship that mentions her birth.\", \"useful_relationships\": [\"[11] Richard the Lionheart led the Third Crusade\", \"[7] Eleanor was the mother of Richard the Lionheart\", \"[1] Eleanor was born in 1122\"]}\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d76251b",
   "metadata": {},
   "source": [
    "#### Create Query Prompt Template\n",
    "\n",
    "Next, we define the template for formatting new queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c479a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_prompt_template = \"\"\"Question:\n",
    "{question}\n",
    "\n",
    "Relationship descriptions:\n",
    "{relation_des_str}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0787ada2",
   "metadata": {},
   "source": [
    "#### Implement the Reranking Function\n",
    "\n",
    "Now we implement the core reranking function that processes candidate relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36875f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_relations(\n",
    "    query: str, relation_candidate_texts: list[str], relation_candidate_ids: list[str]\n",
    ") -> list[int]:\n",
    "    \"\"\"\n",
    "    Re-rank candidate relations using LLM to select the most relevant ones for answering a query.\n",
    "    \n",
    "    This function uses a large language model with Chain-of-Thought prompting to analyze\n",
    "    candidate relationships and select the most useful ones for answering the given query.\n",
    "    It employs a one-shot learning approach with a predefined example to guide the LLM's\n",
    "    reasoning process.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The input question that needs to be answered.\n",
    "        relation_candidate_texts (list[str]): List of candidate relationship descriptions.\n",
    "        relation_candidate_ids (list[str]): List of IDs corresponding to the candidate relations.\n",
    "        \n",
    "    Returns:\n",
    "        list[int]: A list of relation IDs ranked by their relevance to the query.\n",
    "    \"\"\"\n",
    "    relation_des_str = \"\\n\".join(\n",
    "        map(\n",
    "            lambda item: f\"[{item[0]}] {item[1]}\",\n",
    "            zip(relation_candidate_ids, relation_candidate_texts),\n",
    "        )\n",
    "    ).strip()\n",
    "    rerank_prompts = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            HumanMessage(query_prompt_one_shot_input),\n",
    "            AIMessage(query_prompt_one_shot_output),\n",
    "            HumanMessagePromptTemplate.from_template(query_prompt_template),\n",
    "        ]\n",
    "    )\n",
    "    rerank_chain = (\n",
    "        rerank_prompts\n",
    "        | llm.bind(response_format={\"type\": \"json_object\"})\n",
    "        | JsonOutputParser()\n",
    "    )\n",
    "    rerank_res = rerank_chain.invoke(\n",
    "        {\"question\": query, \"relation_des_str\": relation_des_str}\n",
    "    )\n",
    "    rerank_relation_ids = []\n",
    "    rerank_relation_lines = rerank_res[\"useful_relationships\"]\n",
    "    id_2_lines = {}\n",
    "    for line in rerank_relation_lines:\n",
    "        id_ = int(line[line.find(\"[\") + 1 : line.find(\"]\")])\n",
    "        id_2_lines[id_] = line.strip()\n",
    "        rerank_relation_ids.append(id_)\n",
    "    return rerank_relation_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba48cc17",
   "metadata": {},
   "source": [
    "#### Execute the Reranking Process\n",
    "\n",
    "Finally, we apply the reranking function to our candidate relationships:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c612602",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_relation_ids = rerank_relations(\n",
    "    query,\n",
    "    relation_candidate_texts=relation_candidate_texts,\n",
    "    relation_candidate_ids=relation_candidate_ids,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f37483",
   "metadata": {},
   "source": [
    "### Get Final Results\n",
    "\n",
    "We can get final retrieved passages from the reranked relationships. The final step demonstrates the power of our Graph RAG approach by comparing it directly with traditional RAG methods. This comparison reveals why graph-based reasoning is essential for complex multi-hop questions.\n",
    "\n",
    "**Our Method - Graph RAG Process**:\n",
    "1. Start with re-ranked relationships from LLM filtering\n",
    "2. Map relationships back to their source passages using `relationid_2_passageids`\n",
    "3. Collect unique passages while preserving relevance order\n",
    "4. Return the top-k most relevant passages for answer generation\n",
    "\n",
    "**Baseline - Naive RAG Process**:\n",
    "1. Directly search the passage collection using query embeddings\n",
    "2. Return top-k most semantically similar passages\n",
    "3. No consideration of entity relationships or graph structure\n",
    "\n",
    "**Key Differences**:\n",
    "- **Graph RAG**: Reasons through entity relationships to find relevant context\n",
    "- **Naive RAG**: Relies solely on surface-level semantic similarity between query and passages\n",
    "\n",
    "**Expected Outcome**: For multi-hop questions like \"What contribution did the son of Euler's teacher make?\", our Graph RAG approach should:\n",
    "- **Identify the reasoning chain**: Euler → Johann Bernoulli (teacher) → Daniel Bernoulli (son) → contributions\n",
    "- **Retrieve relevant passages**: Find passages about Daniel Bernoulli's contributions to fluid dynamics\n",
    "- **Provide accurate answers**: Generate responses based on the correct contextual information\n",
    "\n",
    "In contrast, naive RAG might retrieve passages about Euler directly or miss the multi-hop connection entirely, leading to incomplete or incorrect answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f7b89b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_top_k = 2\n",
    "\n",
    "final_passages = []\n",
    "final_passage_ids = []\n",
    "for relation_id in rerank_relation_ids:\n",
    "    for passage_id in relationid_2_passageids[relation_id]:\n",
    "        if passage_id not in final_passage_ids:\n",
    "            final_passage_ids.append(passage_id)\n",
    "            final_passages.append(passages[passage_id])\n",
    "passages_from_our_method = final_passages[:final_top_k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0da55c",
   "metadata": {},
   "source": [
    "We can compare the results with the naive RAG method, which retrieves the topK passages based on the query embedding directly from the passage collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a61ad0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passages retrieved from naive RAG: \n",
      "['Leonhard Euler (1707–1783) was one of the greatest mathematicians of all time, and his\n",
      "relationship with the Bernoulli family was significant. Euler was born in Basel and was a student of\n",
      "Johann Bernoulli, who recognized his exceptional talent and mentored him in mathematics. Johann\n",
      "Bernoulli’s influence on Euler was profound, and Euler later expanded upon many of the ideas and\n",
      "methods he learned from the Bernoullis.', 'Daniel Bernoulli (1700–1782): The son of Johann\n",
      "Bernoulli, Daniel made major contributions to fluid dynamics, probability, and statistics. He is\n",
      "most famous for Bernoulli’s principle, which describes the behavior of fluid flow and is fundamental\n",
      "to the understanding of aerodynamics.']\n",
      "\n",
      "Passages retrieved from our method: \n",
      "['Leonhard Euler (1707–1783) was one of the greatest mathematicians of all time, and his\n",
      "relationship with the Bernoulli family was significant. Euler was born in Basel and was a student of\n",
      "Johann Bernoulli, who recognized his exceptional talent and mentored him in mathematics. Johann\n",
      "Bernoulli’s influence on Euler was profound, and Euler later expanded upon many of the ideas and\n",
      "methods he learned from the Bernoullis.', 'Daniel Bernoulli (1700–1782): The son of Johann\n",
      "Bernoulli, Daniel made major contributions to fluid dynamics, probability, and statistics. He is\n",
      "most famous for Bernoulli’s principle, which describes the behavior of fluid flow and is fundamental\n",
      "to the understanding of aerodynamics.']\n",
      "\n",
      "\n",
      "Answer from naive RAG: The contribution that the son of Euler's teacher, Johann Bernoulli, made was significant in the\n",
      "fields of fluid dynamics, probability, and statistics. Daniel Bernoulli is most famous for\n",
      "Bernoulli’s principle, which describes the behavior of fluid flow and is fundamental to the\n",
      "understanding of aerodynamics.\n",
      "\n",
      "Answer from our method: The contribution that the son of Euler's teacher, Johann Bernoulli, made was significant in the\n",
      "fields of fluid dynamics, probability, and statistics. Daniel Bernoulli is most famous for\n",
      "Bernoulli’s principle, which describes the behavior of fluid flow and is fundamental to the\n",
      "understanding of aerodynamics.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "naive_passage_res = milvus_client.search(\n",
    "    collection_name=passage_col_name,\n",
    "    data=[query_embedding],\n",
    "    limit=final_top_k,\n",
    "    output_fields=[\"text\"],\n",
    ")[0]\n",
    "passages_from_naive_rag = [res[\"entity\"][\"text\"] for res in naive_passage_res]\n",
    "\n",
    "print(\n",
    "    f\"Passages retrieved from naive RAG: \\n{textwrap.fill(str(passages_from_naive_rag), 100)}\\n\\n\"\n",
    "    f\"Passages retrieved from our method: \\n{textwrap.fill(str(passages_from_our_method), 100)}\\n\\n\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"human\",\n",
    "            \"\"\"Use the following pieces of retrieved context to answer the question. If there is not enough information in the retrieved context to answer the question, just say that you don't know.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\"\"\",\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "answer_from_naive_rag = rag_chain.invoke(\n",
    "    {\"question\": query, \"context\": \"\\n\".join(passages_from_naive_rag)}\n",
    ")\n",
    "answer_from_our_method = rag_chain.invoke(\n",
    "    {\"question\": query, \"context\": \"\\n\".join(passages_from_our_method)}\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Answer from naive RAG: {textwrap.fill(str(answer_from_naive_rag), 100)}\\n\\nAnswer from our method: {textwrap.fill(str(answer_from_our_method), 100)}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
